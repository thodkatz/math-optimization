\documentclass[a4paper,11pt]{article}
\usepackage[utf8]{inputenc}


%math  
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{theorem}
\usepackage{pstricks}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{enumitem}
\usepackage{ifthen}     % if-then-else command
\usepackage{euscript}
\usepackage{mathrsfs}   % 
\usepackage{tabu}
\usepackage{rotating}
\newtheorem{theorem}{Theorem}[section]     %
\newtheorem{definition}{Definition}[section]  %
\newtheorem{proof}{Proof}[section]  %
\newtheorem{lemma}{Lemma}[section]  %
\newtheorem{proposition}{Proposition}[section] %
\newtheorem{remark}{Remark}[section] %
\DeclareMathOperator{\sgn}{sgn} % enable partial derivative
\usepackage[super]{nth} % enable easy first and second etc
\usepackage{comment} % to enable block of comment
\DeclareMathOperator*{\argmax}{arg\,max} %enable argmax
\DeclareMathOperator*{\argmin}{arg\,min} %enable argmin
\newcommand{\innerproduct}[2]{\langle #1, #2 \rangle} %enable innerproduct

\usepackage{longtable}
\usepackage{pdfpages}

%formatting
\usepackage{hyphenat}
\usepackage{enumerate}  % tm make it possible to define the numbers (A,a, ...)
\usepackage{float}      % you can define 'H' so that floats are forced to be putted 'here'
\usepackage{afterpage}  % adds \afterpage command, which makes it possible to issue \afterpage{\clearpage} which flushes all floats after this page
\usepackage{rotating}
\usepackage{ulem}       % for underlining text \ul{...}
\usepackage{derivative} % for partial deivative

%graphics
\usepackage{epic,eepic}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{tabularx}
\usepackage{bigstrut}
\usepackage{color, xcolor}

% code
\usepackage[framed,numbered,autolinebreaks,useliterate]{mcode}

%tables
\usepackage{listings}
\usepackage{tabularx}
\usepackage{multirow}   % multirow{nrows}[bigstruts]{width}[fixup]{text} multirow cells
\usepackage{listings}
\usepackage{hhline}     % generates nicer table lines (without missing pixels) + more flexible
\usepackage{colortbl}   % for coloured columns
\usepackage{threeparttable} % adds the possibility to add footnotes in tables
\usepackage{longtable}  %for tables spanning multiple pages

%referencing
\usepackage{cite}
\usepackage{bbm}
\usepackage{url}
\usepackage{hyperref}
\hypersetup{colorlinks=true,
            citecolor=black,
            linkcolor=red,
            citebordercolor=blue,
            urlcolor=magenta,
            linktocpage,
            plainpages=false}
\usepackage{listings}
\usepackage{comment}
\numberwithin{equation}{section} % for the formulas order

%Matlab code
\usepackage{listings}
%\usepackage[framed,numbered,autolinebreaks,useliterate]{mcode}

%----------------------
\PassOptionsToPackage{normalem}{ulem}
\topmargin 0.4cm
\oddsidemargin -0.1cm
\textwidth  15cm
\headheight 0.0cm
\textheight 22.2cm
\parindent  0mm
\parskip    10pt
\tolerance  1000
%----------------------

\title{Technical Report}
\author{Theodors Katzalis}
\date{March 2023}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Introduction}
\label{intro}

\subsection{Study Phase} (this subsection can be remove in final report)

Part 1: Line Search methods

\begin{itemize}
\item Chapter 1 and Chapter 2 of ref.1
\item Chapter 3 : Sections 3.1, 3.2, 3.3 and 3.5 of ref.1
\item Zhang, H. and Hager, W.W. (2004) A Nonmonotone Line Search Technique and Its Application to Unconstrained Optimization. SIAM Journal on Optimization, 14, 1043-
1056.
\end{itemize}

Part 2: Quasi-Newton methods
\begin{itemize}
\item Chapter 6 : Sections 6.1 and 6.4 of ref.1
\item Chapter 7 : Section 7.2 of ref.1
\item Chapter 2 : Section 2.2 of ref.2
\end{itemize}

Part 3: L-BFGS-B
\begin{itemize}

\item Byrd, R. H.; Lu, P.; Nocedal, J.; Zhu, C. (1995). A Limited Memory Algorithm for
Bound Constrained Optimization. SIAM J. Sci. Comput. 16 (5): 1190–1208.
doi:10.1137/0916069. S2CID 6398414.

\item Zhu, C.; Byrd, Richard H.; Lu, Peihuang; Nocedal, Jorge (1997). L-BFGS-B: Algorithm 778: L-BFGS-B, FORTRAN routines for large scale bound constrained optimization. ACM Transactions on Mathematical Software. 23 (4): 550–560.

\item Morales, J. L.; Nocedal, J. (2011). Remark on quote;algorithm 778: L-BFGS-B: 
Fortran subroutines for large-scale bound constrained optimization; ACM Transactions on Mathematical Software. 38: 1–4.

\end{itemize}

References
\begin{itemize}
 \item Ref. 1: Numerical optimization, J. Nocedal and S. Wright, Second Edition (digital copy of the book can be found \url{https://www.csie.ntu.edu.tw/~r97002/temp/num_optimization.pdf}
\item Ref. 2: Nonlinear programming, D. Bertsekas, Third Edition, Athena Scientfic.
\end{itemize}

Knowledge consolidation of math optimization around Quasi-Newton methods via concept summarizing and exercises solving of \cite{nocedal1999numerical, bertsekas1997nonlinear}.

\subsection{Updates}
\begin{itemize}
    \item \textbf{Week 11-18/04/2023:} 
    \begin{itemize}
        \item Add documentation to the functions `newton.m` and `steepest\_descent.m` with examples on how to use it. Otherwise, the jupyter notebook can be used as a reference point on how to call these methods.
        \item Add wolfe strong line search method. For the interpolation step, we use the simple bisection method instead of a more sophisticated solution with cubic or quadratic interpolation.
        \item Add more functions with more than 2 dimensions as provided on mattermost to test the functions.
        \item Add plots when finishing the executing of the line search methods to illustrate the progress of the algorithm.
        \item The jupyter notebook has been updated to include the new functions and to show the plots. (Currently a pdf is exported to include it on this report. When there is access to a git host system, a link will be used to avoid the sync issue).
    \end{itemize}
    \item \textbf{Week 18-27/04/2023:}
    \begin{itemize}
        \item Document how to execute the functions and provide a demo script along with the jupyter notebook (moved to appendix).
        \item Use new starting points.
        \item Draw 3d plots using contour and 3d lines.
        \item Create a table with the results of the analysis.
    \end{itemize}
    \item \textbf{Week 28-04/05/2023:}
    \begin{itemize}
        \item Implement the nonmonotone line search technique of Zhang-Hager.
    \end{itemize}
    \item \textbf{Week 05-11/05/2023:}
    \begin{itemize}
        \item Implement the nonmonotone line search technique of Grippo.
        \item Implement the bisection wolfe weak condition and replace it with the faulty backtracking wolfe weak implementation.
        \item Add Goldstein condition as a curvature condition. Mimic the wolfe weak implementation.
        \item Automate simulation of all the possible combinations of line search techniques and step sizes and create a csv file
        \item Create tables for the results of the above simulation, converting csv to tex tables.
        \item Improve performance of simulations, by using the \verb|function_handle| to convert symbolic functions to function handlers.
    \end{itemize}
    \item \textbf{Week 11-15/05/2023:}
    \begin{itemize}
        \item Document inexact line/step length search strategies (wolfe, armijo, goldstein) and type of conditions (sufficient, curvature)
        \item Add number of function evaluations and number of gradient of function evaluations as metrics for the simulations
    \end{itemize}
    \item \textbf{Week 15-25/05/2023:}
    \begin{itemize}
        \item Debugging divergence of algorithms (+ why are we getting imaginary numbers?).
        \item Adjust the initial alpha value to be within boundaries so the value $x+a*pk$ stays within function's domain.
        \item Add more conclusions about the behaviour of the optimization algorithms.
    \end{itemize}
\end{itemize}
 
\pagebreak

\section{Theoretical Experiments}

Problems listed on Chapter 2 of ref \cite{nocedal1999numerical}:

\label{rosenbrock}
\subsection{}

\textbf{Problem}

Compute the gradient $\nabla f(x)$ and Hessian $\nabla^2 f(x)$ of the Rosenbrock function.

\begin{equation}
    f(x) = 100(x_2 -x_1^2)^2 + (1-x_1)^2 
\end{equation}

Show that $x^{\ast} = (1, 1)^{T}$ is the only local minimizer of this function, and that the Hessian matrix at that point is positive definite.


\textbf{Solution}

\begin{align}
    \nabla f(x) &= (\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}) \\
    \nabla f(x) &= (2(200x_1^3 -200x_2x_1 + x_1- 1)), 200(x_2 - x_1^2)) \\
    \nabla^2 f(x) &= 
    \begin{bmatrix}
    800x_1^2 - 400(x_2 - x_1^2) +2 & -400x_1 \\
    -400x_1 & 200
    \end{bmatrix}
\end{align}

To find all the possible stationary points and potentially the local minimums we solve $\nabla f(x) =0$ and the only root is $x^{*} = (1,1)$. To check if the stationary point is a local minimum and this case a global minimum, since there aren't any other stationary points, then we have to check if $\nabla^2 f(x^{*})$ is positive definitive and we have:

\begin{equation}
    \nabla^2 f(1,1) = 
    \begin{bmatrix}
        802 & -400 \\
        -400 & 200
    \end{bmatrix}
\end{equation}

The eigenvalues for the above matrix are $\lambda_1 \approx 1001.6$ and $\lambda_2 \approx 0.399361$. We can prove that the matrix is positive definite. Thus, the $x^{*} = (1,1)$ is the global minimum of the Rosenbrock function.

\subsection{}

\textbf{Problem}

Show that the function $f(x) = 8x_1 + 12x_2 + x_1^2 - 2x_2^2$ has only one stationary
point, and that it is neither a maximum or minimum, but a saddle point. Sketch the contour
lines of f.

\textbf{Solution}


To find the stationary points we solve $\nabla f(x) = 0$ and we have:
\begin{equation}
    \nabla f(x) = (2(x+4), -4(y-3)
\end{equation}
, thus the only root is $x^{*} = (-4, 3)$. To prove that it is a saddle point, we have to show that some of the eigenvalues of the Hessian matrix are positive and the rest negative. Thus we have:

\begin{equation}
    \nabla^2 f(x) = 
    \begin{bmatrix}
        2 & 0 \\
        0 & -4
    \end{bmatrix}
\end{equation}

and eigenvalues $\lambda_1 = -4$ and $\lambda_2 = 2$. The first is positive and the second is negative. Thus, we have proved that the point $(-4, 3)$ is a saddle one.

\begin{figure}[h!]
     \centering
     \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{assets/saddle_3d.png}
         \caption{3D}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{assets/saddle_contour.png}
         \caption{Contour lines}
     \end{subfigure}
    \caption{}
\end{figure}

\subsection{}

\textbf{Problem}

Let a be a given n-vector, and A be a given n × n symmetric matrix. Compute the
gradient and Hessian of $f_1(x) = a^T x$ and $f_2(x) = x^TAx$.

\textbf{Solution}

For the $f_1$, we have:

\begin{align}
    \nabla f_1(x) &= a \\
    \nabla^2 f_1(x) &= 0
\end{align}

, due to the fact that the vector $a$ is constant.

For the $f_2$, we have:

\begin{align}
    \nabla f_2(x) &= 2Ax \\
    \nabla^2 f_2(x) &= 2A
\end{align}

\subsection{}

\textbf{Problem}

Write the second-order Taylor expansion (2.6) for the function cos(1/x) around
a nonzero point x, and the third-order Taylor expansion of cos(x) around any point x. Evaluate the second expansion for the specific case of x = 1.

\textbf{Solution}

For the second order taylor expansion of $cos(1/x)$ near the point $x_0$ we have:

\begin{equation}
cos(1/x)) = cos(1/x_0) + \frac{sin(1/x_0)}{x_0^2 (x-x_0)} - \frac{1}{2} \frac{2x_0*sin(1/x_0) + cos(1/x_0)}{x_0^4(x-x_0)^2}
\end{equation}

For the third order taylor expansion of $cos(x)$ near the point $x_0$, we have:

\begin{equation}
    cos(x) = cos(x_0) - (x-x_0)sin(x_0) - \frac{(x-x_0)^2}{2}cos(x_0) + \frac{(x-x_0)^3}{6}sin(x_0)
\end{equation}

\subsection{}

\textbf{Problem}

Consider the function f: $R^2 \rightarrow R$ defined by $f(x) = {||x||}^2$. Show that the sequence of iterates {$x_k$} defined by

\[x_k = (1 + \frac{1}{2^k}) \begin{bmatrix}
    cosk \\ sink
\end{bmatrix}\]

satisfies $f(x_{k+1} < f(x_k)$ for k = 0, 1, 2, .... Show that every point on the unit circle $\{x | {||x||}^2 = 1\}$ is a limit point for {$x_k$}.

\textbf{Solution}

\begin{align}
    f(x_k) &= (1+\frac{1}{2^k})^2(cos^2k + sin^2k) \\
    f(x_k) &= (1+\frac{1}{2^k})^2
\end{align}

For the inequality, we have:

\begin{align}
    f(x_{k+1}) &< f(x_k) \\
    (1 + \frac{1}{2^{k+1}})^2 &< (1 + \frac{1}{2^k})^2 \\ 
    k+1 &> k
\end{align}

, that is true.

Also, because $\lim_{k\to\infty} f(x_k) = 1$ and $f(x_{k+1}) < f(x_k)$, the points of the unit circle are limit points for {$x_k$}.

\subsection{}

\textbf{Problem}

Prove that all isolated local minimizers are strict. (Hint: Take an isolated local
minimizer $x^{*}$ and a neighborhood N . Show that for any $x \in N$ , $x \neq x^{*}$ we must have $f(x) > f(x^{*})$.)

\textbf{Solution}

By definition a point $x^{*}$ of $f$ is strict when there is a neighborhood N such that $f(x^{*}) < f(x)$ for all $x \in N$ with $x \neq x^{*}$.

By definition a point $x^{*}$ is an isolated local minimizer if there is a neighborhood N of $x^{*}$ such that the $x^{*}$ is the only local minimizer in N.

Let's suppose that given an isolated local minimer $x^{*}$ for a neighbor N, then $f(x) \leq f(x^{*})$ for $x \in N$ and $x \neq x^{*}$. Then the minimizer $x^{*}$ isn't the only one, thus isn't isolated. Thus it should be $f(x) > f(x^{*})$. The last one completes the definition of a strict minimizer. Thus we have proved that an isolated minimer is a strict one.




\section{Numerical Experiments}

In this section, we will test well-known optimization techniques with multiple step size strategies on a different set of functions. 
The in-house implementation of the above can be found at the \ref{code}.
For an example on how to use the functions you can check the \verb|demo.m| and the jupyter notebook.

The line search techniques are based on the simple iterative formula of $x_{k+1} = x_k + a_k pk$, where $p_k$ is the direction vector and $a_k$ is the step size. For the $pk$, we will study two main schools of thought, the newton method and the steepest descent. On the other hand for the step size, we will study many different approaches such as (\verb|grippo|, \verb|Hanger and Zhang|, \verb|backtracking|, \verb|bisection wolfe weak|, \verb|wolfe strong|, \verb|goldstein|). 

Our goal is to find $a_k$ that minimizes the function $\phi (a) = f(x_k + a pk)$. To find an exact answer is computationally expensive, so usually inexact search strategies are incorporated. Typical step size search algorithms try out a sequence of candidate values for $\alpha$, stopping to
accept one of these values when certain conditions are satisfied.
An effective condition that leads to a decrease of a function while ensuring convergence, is the so called \textbf{sufficient decrease condition}:

\begin{equation}
f(x_k + a p_k) \leq f(x_k) + a  c_1 p_k^T \nabla f_k
\end{equation}

This condition is also called \textbf{Armijo condition}, where $c_1 \in (0,1)$.

The sufficient decrease condition is not enough by itself to ensure that the algorithm
makes reasonable progress. To rule out unacceptably short steps we introduce a second requirement,
called the \textbf{curvature condition}, which requires $a_k$ to satisfy:

\begin{equation}
c_2 \nabla f_k^Tp_k \le \nabla f(x_k + a p_k)^T p_k
\end{equation}

, where $c2 \in (c_1,1)$. The sufficient decrease and curvature conditions are known collectively as the \textbf{Wolfe
conditions}.

There is also another similar pair of conditions called the \textbf{strong Wolfe} conditions:

\begin{align}
f(x_k + a p_k) &\leq f(x_k) + a  c_1 p_k^T \nabla f_k \\
|\nabla f(x_k + a p_k)^T p_k| &\le c_2  |\nabla f_k^Tp_k|
\end{align}

The only difference with the Wolfe conditions is that we no longer
allow the derivative $\nabla f(x_k + a_k  p_k)$ to be too positive. Hence, we exclude points that are far from stationary points of $f(x_k + a_k p_k)$.


Like the Wolfe conditions, the \textbf{Goldstein} conditions ensure that the step length $\alpha$
achieves sufficient decrease but is not too short. The Goldstein conditions can also be stated
as a pair of inequalities, in the following way:

\begin{align}
    f(x_k + a_k pk) &\leq f(x_k) + a_k c \nabla f_k^T p_k \\
    f(x_k) + a_k (1-c) \nabla f_k^T p_k & \le f(x_k + a_k p_k) 
\end{align}

, where $0 < c < 1/2$. The first inequality is the sufficient decrease, and similarly with the Wolfe, the second one can be assumed as the curvature condition. A key difference between the Wolfe and the Goldstein conditions is that for the first there are two independent variables to configure $c_1$ and $c_2$, but for the second, only one $c$.


% The steps are:
% \begin{itemize}
%     \item Include all the ".m" files in the path (\verb|addpath()|)
%     \item Define a symbolic function
%     \item Pick a number from 1-4 to choose your step size configuration (1: Backtracking wolfe weak, 2: Wolfe stong, 3: Backtracking armijo, 4: None)
%     \item Pick a starting point e.g. \verb|[1,1]'|
%     \item Pick a search domain for the plots e.g. \verb|search_x = -1:-0.1:1|, \verb|search_y = -1:0.1:1|
% \end{itemize}

\subsection{}


Test on problem functions 1: Ext; Rosenbrock, 2: Wood, 3: Powell singular, 4: Cube, 5: Trigonometric, 6: Helical valley (ref. page 713 Grippo), the following line search techniques:
    
\begin{itemize}
    \item Grippo/max with Armijo
    \item Grippo/max with Armijo + Goldstein (lower bound)
    \item Grippo/max with Wolfe condition (open)
    \item Comparison with Hagher \& Zhang with Steepest descent \& Newton: a) Armijo, b) Wolfe
    \item Comparison with monotone Armijo + Goldstein
\end{itemize}

\begin{align*}
    rosen(n) &= \sum_{i=1}^{n-1} [100 (x_{i+1}-x_i^2)^2 + (1-x_i)^2], \\ &\quad x_0 = [-1.2,1,...,-1.2,1], \quad f_{min}(1,1,...,1,1)=0  \\
    wood(x_1,x_2,x_3,x_4) &= 100*(x_1^2-x_2)^2 + (x_1-1)^2 + (x_3-1)^2 + 90*(x_3^2 - x_4)^2 + \\ & 10.1*((x_2-1)^2 + (x_4-1)^2) + 19.8*(x_2-1)*(x_4-1)\\ & \quad x_0 [-3,-1,-3,-1], \quad f_{min}(1,1,1,1) = 0 \\
    powell(x_1,x_2,x_3,x_4) &= (x_1+10*x_2) + 5*(x_3-x_4)^2 + (x_2-2*x_3)^4 + 10*(x_1-x_4)^2 \\ & \quad x_0 = [3,-1.0,1], \quad f_{min}(0,0,0,0) = 0 \\
    cube(x_1,x_2) &= 100(x_2-x_1^3)^2 + (1-x_1)^2 \\ & \quad x_0 = [-1.2,-1], \quad f_{min}(1,1) = -6.4931 \\ 
    trig(n) &= \sum_{i=1}^{n}[n + i(1-cosx_i) - sinx_i - \sum_{j=1}^{n}cosx_j]^2,\\ & \quad x_0 = [1/5n,...1/5n], \quad f_{min}(0,...,0) = 0 \\
    helical(x_1,x_2,x_3) &= 100[(x_3-10\theta)^2 + (\sqrt{x_1^2+x_2^2}-1)^2] + x_3^2, \\ & \quad x_0 = [-1,0,0], \quad f_{min}(1,0,0) = 0 \\
\end{align*}

For the results, check the \ref{simulation2}.

\subsubsection{Numerical Results}
\label{simulation2}

\textbf{Wolfe strong}

\begin{align*}
a &= 1 \\
rho &= 2 \\
c1 &= 1e-4 \\
c2 &= 0.9 \\
eps &= 1e-16 \\ 
max\_iters &= 5000 \\ 
max\_iters\_step\_size &= 50 \\
max\_iters\_zoom &= 10 \\
\end{align*}

\textbf{Non wolfe methods}

\begin{align*}
a &= 1 \\
rho &= 0.6 \\
c &= 0.1 \\
eps &= 1e-16 \\ 
max\_iters &= 5000 \\ 
max\_iters\_step\_size &= 50 \\
\end{align*}

For grippo, we have added the $memory\_limit = 10$ parameter.


\begin{table}[h!]
\resizebox{1.2\textwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}
        method & step size & iterations & $n_{f\_eval}$ & $n_{fgrad\_eval}$ &error x1 & error x2 & error fvalue \\ \hline
newton & backtracking\_armijo & 25 & 58 & 74 & 0 & 0 & 0 \\
        newton & wolfe\_strong & 5000 & 59271 & 19697 & 2.44249065417534e-15 & 4.88498130835069e-15 & 5.9657605957339e-30 \\
        newton & bisection\_wolfe\_weak & 26 & 83 & 109 & 0 & 0 & 0 \\
        newton & bisection\_goldstein & 27 & 213 & 80 & 0 & 0 & 0 \\
        newton & hanger\_zhang\_backtracking\_armijo & 18 & 43 & 53 & 0 & 0 & 0 \\
        newton & hanger\_zhang\_bisection\_wolfe\_weak & 17 & 55 & 72 & 0 & 0 & 0 \\
        newton & hanger\_zhang\_wolfe\_strong & 77 & 164 & 3 & 0 & 0 & 0 \\
        newton & hanger\_zhang\_bisection\_goldstein & 17 & 77 & 50 & 0 & 0 & 0 \\
        newton & grippo\_backtracking\_armijo & 14 & 33 & 41 & 0 & 0 & 0 \\
        newton & grippo\_bisection\_wolfe\_weak & 15 & 47 & 62 & 0 & 0 & 0 \\
        newton & grippo\_wolfe\_strong & 77 & 164 & 3 & 0 & 0 & 0 \\
        newton & grippo\_bisection\_goldstein & 15 & 65 & 44 & 0 & 0 & 0 \\
        steepest & backtracking\_armijo & 5000 & 69617 & 10000 & 0.00134280231167772 & 0.00268394592540899 & 1.8031201339636e-06 \\
        steepest & wolfe\_strong & 5000 & 51877 & 19879 & 0.00252209654092062 & 0.00202163276960365 & 0.000916106817593004 \\
        steepest & bisection\_wolfe\_weak & 5000 & 59664 & 59663 & 0.000664113755119433 & 0.0013272657620409 & 4.41074192704286e-07 \\
        steepest & bisection\_goldstein & 5000 & 109597 & 10000 & 0.000107277792954052 & 0.000215211299631424 & 1.15500248948724e-08 \\
        steepest & hanger\_zhang\_backtracking\_armijo & 5000 & 67868 & 10000 & 0.160363681632484 & 0.329452632917246 & 0.144340131612232 \\
        steepest & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 59885 & 59884 & 0.0718072832230432 & 0.166132292209885 & 0.0817413782128194 \\
        steepest & hanger\_zhang\_wolfe\_strong & 5000 & 50081 & 12383 & 0.0977164567781574 & 0.141482096145648 & 0.206705032449827 \\
        steepest & hanger\_zhang\_bisection\_goldstein & 5000 & 108477 & 10000 & 0.0549135538452912 & 0.152474365190608 & 0.211524225997189 \\
        steepest & grippo\_backtracking\_armijo & 5000 & 71933 & 10000 & 0.0111060251915582 & 0.0221575522908883 & 0.000126506569260569 \\
        steepest & grippo\_bisection\_wolfe\_weak & 5000 & 65755 & 65754 & 0.365344749870128 & 0.861031213722145 & 0.134459654075102 \\
        steepest & grippo\_wolfe\_strong & 5000 & 52962 & 20000 & 0.00294880967191391 & 0.00333491693247834 & 0.000669904189263771 \\
        steepest & grippo\_bisection\_goldstein & 5000 & 107089 & 10000 & 0.00048166962845908 & 0.000957123991054853 & 2.35585571280745e-07 \\
\end{tabular}}
\caption{rosen(2)}
\label{table:rosen(2)}
\end{table}

\begin{table}[h!]
\resizebox{1.2\textwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}
        method & step size & iterations & $n_{f\_eval}$ & $n_{fgrad\_eval}$ &error x1 & error x2 & error fvalue \\ \hline
newton & backtracking\_armijo & 5000 & 253390 & 15000 & 0 & 4.44089209850063e-16 & 1.29422492262822e-30 \\
        newton & wolfe\_strong & 5000 & 59271 & 15410 & 1.99326337285637 & 0.0116073698712496 & 3.98657911234714 \\
        newton & bisection\_wolfe\_weak & 5000 & 258292 & 263291 & 0 & 7.99360577730113e-15 & 2.36904790599185e-29 \\
        newton & bisection\_goldstein & 5000 & 506583 & 15000 & 0 & 7.99360577730113e-15 & 2.36904790599185e-29 \\
        newton & hanger\_zhang\_backtracking\_armijo & 5000 & 10001 & 15000 & 0 & 8.88178419700125e-16 & 2.73636126498538e-30 \\
        newton & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 15001 & 20000 & 0 & 8.88178419700125e-16 & 2.73636126498538e-30 \\
        newton & hanger\_zhang\_wolfe\_strong & 5000 & 34061 & 3 & 1.99326337285637 & 0.0116073698711289 & 3.98657911234714 \\
        newton & hanger\_zhang\_bisection\_goldstein & 5000 & 20001 & 15000 & 0 & 8.88178419700125e-16 & 2.73636126498538e-30 \\
        newton & grippo\_backtracking\_armijo & 5000 & 252610 & 15000 & 0 & 8.88178419700125e-16 & 1.49144014893348e-30 \\
        newton & grippo\_bisection\_wolfe\_weak & 5000 & 258090 & 263089 & 0 & 8.88178419700125e-16 & 1.49144014893348e-30 \\
        newton & grippo\_wolfe\_strong & 5000 & 59164 & 19661 & 1.99326337285637 & 0.0116073698711348 & 3.98657911234714 \\
        newton & grippo\_bisection\_goldstein & 5000 & 505219 & 15000 & 0 & 8.88178419700125e-16 & 1.49144014893348e-30 \\
        steepest & backtracking\_armijo & 5000 & 74764 & 10000 & 5.48540028638689e-05 & 0.0286841787479997 & 0.000277704522732761 \\
        steepest & wolfe\_strong & 5000 & 56265 & 20000 & 3.93810395428185e-05 & 0.0423672161711592 & 0.000770240715919961 \\
        steepest & bisection\_wolfe\_weak & 5000 & 63088 & 63087 & 7.16228404579189e-05 & 0.0380130729504465 & 0.000490781743850277 \\
        steepest & bisection\_goldstein & 5000 & 116345 & 10000 & 7.00100124008118e-05 & 0.0368001035345523 & 0.00045939348961148 \\
        steepest & hanger\_zhang\_backtracking\_armijo & 5000 & 55581 & 10000 & 0.901097368455062 & 0.999908203431852 & 13.5979762468086 \\
        steepest & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 48264 & 48263 & 0.926048196131413 & 0.987154855364427 & 14.1333748210494 \\
        steepest & hanger\_zhang\_wolfe\_strong & 5000 & 38264 & 20000 & 0.926048196131413 & 0.987154855364427 & 14.1333748210494 \\
        steepest & hanger\_zhang\_bisection\_goldstein & 5000 & 86611 & 10000 & 0.829944130045016 & 1.00009251746317 & 14.2373631878622 \\
        steepest & grippo\_backtracking\_armijo & 5000 & 74274 & 10000 & 5.89869550274846e-05 & 0.031946540616167 & 0.000345867297706993 \\
        steepest & grippo\_bisection\_wolfe\_weak & 5000 & 62759 & 62758 & 7.49165464006829e-05 & 0.0420641753553341 & 0.000606141821478284 \\
        steepest & grippo\_wolfe\_strong & 5000 & 53542 & 20000 & 0.000164863168950147 & 0.040789355898774 & 0.00578467650472605 \\
        steepest & grippo\_bisection\_goldstein & 5000 & 115783 & 10000 & 6.48742516954348e-05 & 0.0400920184468829 & 0.000561131639128333 \\

\end{tabular}}
\caption{rosen(10)}
\label{table:rosen(10)}
\end{table}

\begin{table}[h!]
\resizebox{1.2\textwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}
        method & step size & iterations & $n_{f\_eval}$ & $n_{fgrad\_eval}$ &error x1 & error x2 & error fvalue \\ \hline
newton & backtracking\_armijo & 5000 & 19933 & 15000 & 1.99328610095495 & 1.27605140213261e-05 & 3.9866238542612 \\
        newton & wolfe\_strong & 5000 & 59211 & 19445 & 1.99328610095495 & 1.27605140972653e-05 & 3.9866238542612 \\
        newton & bisection\_wolfe\_weak & 5000 & 27040 & 32039 & 1.99328610095495 & 1.2760514021215e-05 & 3.9866238542612 \\
        newton & bisection\_goldstein & 5000 & 20007 & 15000 & 1.99328610095495 & 1.2760514021215e-05 & 3.9866238542612 \\
        newton & hanger\_zhang\_backtracking\_armijo & 5000 & 10001 & 15000 & 1.99328610095495 & 1.27605140213261e-05 & 3.9866238542612 \\
        newton & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 15214 & 20213 & 1.99328610095495 & 1.2760514021215e-05 & 3.9866238542612 \\
        newton & hanger\_zhang\_wolfe\_strong & 5000 & 14695 & 1 & 1.99328610095495 & 1.27605140213261e-05 & 3.9866238542612 \\
        newton & hanger\_zhang\_bisection\_goldstein & 5000 & 20005 & 15000 & 1.99328610095495 & 1.2760514021215e-05 & 3.9866238542612 \\
        newton & grippo\_backtracking\_armijo & 5000 & 10001 & 15000 & 1.99328610095495 & 1.27605140213261e-05 & 3.9866238542612 \\
        newton & grippo\_bisection\_wolfe\_weak & 5000 & 15679 & 20678 & 1.99328610095495 & 1.2760514021215e-05 & 3.9866238542612 \\
        newton & grippo\_wolfe\_strong & 5000 & 59053 & 2 & 1.99328610095495 & 1.27605140213261e-05 & 3.9866238542612 \\
        newton & grippo\_bisection\_goldstein & 5000 & 20005 & 15000 & 1.99328610095495 & 1.2760514021215e-05 & 3.9866238542612 \\
        steepest & backtracking\_armijo & 5000 & 75215 & 10000 & 9.78622647807015e-07 & 9.91479123044758e-05 & 0.00279943867596394 \\
        steepest & wolfe\_strong & 5000 & 55019 & 20000 & 1.8327101023452e-05 & 0.000267857515976466 & 0.00446457772395234 \\
        steepest & bisection\_wolfe\_weak & 5000 & 63142 & 63141 & 2.12251526288121e-06 & 0.000124026639927277 & 0.00379777961696662 \\
        steepest & bisection\_goldstein & 5000 & 116571 & 10000 & 1.86700096582726e-06 & 0.000116233720699577 & 0.00340871313465024 \\
        steepest & hanger\_zhang\_backtracking\_armijo & 5000 & 55686 & 10000 & 0.988553504052133 & 0.989748511392169 & 28.1184396198413 \\
        steepest & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 49210 & 49209 & 0.927180277638927 & 0.986610279817029 & 21.8572869641165 \\
        steepest & hanger\_zhang\_wolfe\_strong & 5000 & 39210 & 20000 & 0.927180277638927 & 0.986610279817029 & 21.8572869641165 \\
        steepest & hanger\_zhang\_bisection\_goldstein & 5000 & 86549 & 10000 & 0.926104477205542 & 0.988110125042208 & 19.7068287891131 \\
        steepest & grippo\_backtracking\_armijo & 5000 & 74674 & 10000 & 7.04250320049393e-06 & 4.59855515106966e-05 & 0.00380814909278737 \\
        steepest & grippo\_bisection\_wolfe\_weak & 5000 & 62726 & 62725 & 1.65076020670618e-05 & 0.000259877958470711 & 0.00507214849218104 \\
        steepest & grippo\_wolfe\_strong & 5000 & 53398 & 20000 & 0.000168764255138454 & 0.00129931593131594 & 0.0212844742055927 \\
        steepest & grippo\_bisection\_goldstein & 5000 & 115919 & 10000 & 1.41133015090222e-05 & 7.57607105694724e-06 & 0.00433063577014618 \\
\end{tabular}}
\caption{rosen(20)}
\label{table:rosen(20)}
\end{table}

\begin{table}[h!]
\resizebox{1.2\textwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}
        method & step size & iterations & $n_{f\_eval}$ & $n_{fgrad\_eval}$ &error x1 & error x2 & error fvalue \\ \hline
newton & backtracking\_armijo & 5000 & 254658 & 15000 & 1.99656018326997 & 0.00311063472069217 & 7.87651605718216 \\
        newton & wolfe\_strong & 5000 & 59022 & 19606 & 5.55111512312578e-16 & 1.11022302462516e-15 & 2.00419973732713e-30 \\
        newton & bisection\_wolfe\_weak & 5000 & 246049 & 251048 & 1.99656018457328 & 0.00311063731081251 & 7.87651605713997 \\
        newton & bisection\_goldstein & 5000 & 480721 & 15000 & 1.99656018456255 & 0.0031106372895402 & 7.87651605714032 \\
        newton & hanger\_zhang\_backtracking\_armijo & 5000 & 10001 & 15000 & 1.9679740249376 & 0.0528608591821509 & 7.87696716517687 \\
        newton & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 15949 & 20948 & 3.77475828372553e-15 & 7.66053886991358e-15 & 4.98227291405289e-29 \\
        newton & hanger\_zhang\_wolfe\_strong & 5000 & 47987 & 1 & 4.44089209850063e-16 & 8.88178419700125e-16 & 1.76630887059642e-30 \\
        newton & hanger\_zhang\_bisection\_goldstein & 5000 & 21323 & 15000 & 3.5527136788005e-15 & 7.105427357601e-15 & 4.05918239542787e-29 \\
        newton & grippo\_backtracking\_armijo & 5000 & 12243 & 15000 & 1.96797402493755 & 0.0528608591822334 & 7.87696716517687 \\
        newton & grippo\_bisection\_wolfe\_weak & 5000 & 252863 & 257862 & 3.5527136788005e-15 & 7.105427357601e-15 & 5.36203548420694e-29 \\
        newton & grippo\_wolfe\_strong & 5000 & 59368 & 19453 & 3.33066907387547e-16 & 7.7715611723761e-16 & 2.98657808336017e-30 \\
        newton & grippo\_bisection\_goldstein & 5000 & 495669 & 15000 & 2.77555756156289e-15 & 5.44009282066327e-15 & 2.034644837888e-29 \\
        steepest & backtracking\_armijo & 5000 & 71116 & 10000 & 0.000810904130541745 & 0.00161423398895644 & 2.35694325196137e-06 \\
        steepest & wolfe\_strong & 5000 & 53428 & 20000 & 0.00111107324031523 & 0.00072848442246598 & 0.000878187676163186 \\
        steepest & bisection\_wolfe\_weak & 5000 & 59932 & 59931 & 7.55631828657233e-05 & 0.000150817160219363 & 2.05069546004349e-08 \\
        steepest & bisection\_goldstein & 5000 & 109403 & 10000 & 1.62309737805622e-05 & 3.22987179617318e-05 & 9.44897050478453e-10 \\
        steepest & hanger\_zhang\_backtracking\_armijo & 5000 & 77700 & 10000 & 0.980472012169326 & 2.1155745415018 & 79.2886270800092 \\
        steepest & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 67015 & 67014 & 0.982959937704474 & 1.23534554805625 & 155.234277614323 \\
        steepest & hanger\_zhang\_wolfe\_strong & 5000 & 58167 & 18384 & 3.79448800393189 & 4.768912233649 & 563.453955593612 \\
        steepest & hanger\_zhang\_bisection\_goldstein & 5000 & 116179 & 10000 & 0.767436322311197 & 1.00663982654644 & 31.2108511121769 \\
        steepest & grippo\_backtracking\_armijo & 5000 & 72173 & 10000 & 0.003125656906251 & 0.00640102608518212 & 3.87276261863801e-05 \\
        steepest & grippo\_bisection\_wolfe\_weak & 5000 & 61064 & 61063 & 0.00182792314049773 & 0.00358936800563647 & 1.21502695569954e-05 \\
        steepest & grippo\_wolfe\_strong & 5000 & 61064 & 61063 & inf & inf & inf \\
        steepest & grippo\_bisection\_goldstein & 5000 & 110817 & 10000 & 1.42381918823986e-05 & 2.87471490576507e-05 & 7.45543488161516e-10 \\
\end{tabular}}
\caption{wood}
\label{table:wood}
\end{table}

\clearpage

\textbf{Question}
Why using \verb|steepest descent - Hanger Zhang| has bad performance instead of the newton equivalent?

\textbf{Answer}
The Hanger Zhang method is being tested for second order derivatives methods, and there isn't any analysis for the steepest descent method.

\textbf{Question}
Why \verb|steepest - grippo - wolfe - strong| doesn't converge?

\textbf{Answer}
There is a maximum number of iterations when searching alpha values to satisfy the wole strong conditions. If the number of iterations is reached, then we still return the latest alpha value. But, the last one hasn't satisfy the conditions, thus divergence is possible. Carefully tuning particular cases, could resolve these issues.

\begin{table}[h!]
\resizebox{1.2\textwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}
        method & step size & iterations & $n_{f\_eval}$ & $n_{fgrad\_eval}$ &error x1 & error x2 & error fvalue \\ \hline
newton & backtracking\_armijo & 37 & 73 & 110 & 1.09008279951857e-06 & 1.09008279951857e-07 & 7.07425942202815e-24 \\
        newton & wolfe\_strong & 80 & 159 & 3 & 1.32261614039115e-06 & 1.32261614039115e-07 & 1.53303628540991e-23 \\
        newton & bisection\_wolfe\_weak & 37 & 109 & 146 & 1.09008279951857e-06 & 1.09008279951857e-07 & 7.07425942202815e-24 \\
        newton & bisection\_goldstein & 37 & 145 & 110 & 1.09008279951857e-06 & 1.09008279951857e-07 & 7.07425942202815e-24 \\
        newton & hanger\_zhang\_backtracking\_armijo & 37 & 73 & 110 & 1.09008279951857e-06 & 1.09008279951857e-07 & 7.07425942202815e-24 \\
        newton & hanger\_zhang\_bisection\_wolfe\_weak & 37 & 109 & 146 & 1.09008279951857e-06 & 1.09008279951857e-07 & 7.07425942202815e-24 \\
        newton & hanger\_zhang\_wolfe\_strong & 80 & 159 & 3 & 1.32261614039115e-06 & 1.32261614039115e-07 & 1.53303628540991e-23 \\
        newton & hanger\_zhang\_bisection\_goldstein & 37 & 145 & 110 & 1.09008279951857e-06 & 1.09008279951857e-07 & 7.07425942202815e-24 \\
        newton & grippo\_backtracking\_armijo & 37 & 73 & 110 & 1.09008279951857e-06 & 1.09008279951857e-07 & 7.07425942202815e-24 \\
        newton & grippo\_bisection\_wolfe\_weak & 37 & 109 & 146 & 1.09008279951857e-06 & 1.09008279951857e-07 & 7.07425942202815e-24 \\
        newton & grippo\_wolfe\_strong & 80 & 159 & 3 & 1.32261614039115e-06 & 1.32261614039115e-07 & 1.53303628540991e-23 \\
        newton & grippo\_bisection\_goldstein & 37 & 145 & 110 & 1.09008279951857e-06 & 1.09008279951857e-07 & 7.07425942202815e-24 \\
        steepest & backtracking\_armijo & 5000 & 54340 & 10000 & 0.0392426581127082 & 0.00391883769401818 & 4.92249697826105e-06 \\
        steepest & wolfe\_strong & 5000 & 59594 & 23269 & 0.0301239507848158 & 0.00301319492698273 & 1.71063639028167e-06 \\
        steepest & bisection\_wolfe\_weak & 5000 & 47940 & 47939 & 0.0410571305472712 & 0.00409950691814887 & 5.89685505314996e-06 \\
        steepest & bisection\_goldstein & 5000 & 85879 & 10000 & 0.0410572633120998 & 0.00409941375822155 & 5.89702374026392e-06 \\
        steepest & hanger\_zhang\_backtracking\_armijo & 5000 & 54154 & 10000 & 0.0272146920449809 & 0.109462775389505 & 1.25863518007019 \\
        steepest & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 47929 & 47928 & 0.0234357713942148 & 0.0550934919604873 & 0.329911399836167 \\
        steepest & hanger\_zhang\_wolfe\_strong & 5000 & 37929 & 20000 & 0.0234357713942148 & 0.0550934919604873 & 0.329911399836167 \\
        steepest & hanger\_zhang\_bisection\_goldstein & 5000 & 85859 & 10000 & 0.0244326412665608 & 0.0212069468957112 & 0.0559349556992951 \\
        steepest & grippo\_backtracking\_armijo & 5000 & 53643 & 10000 & 0.0359386388031535 & 0.00358355653909171 & 3.47103535608424e-06 \\
        steepest & grippo\_bisection\_wolfe\_weak & 5000 & 47934 & 47933 & 0.0403367646842427 & 0.00401058033247947 & 5.53784088222752e-06 \\
        steepest & grippo\_wolfe\_strong & 5000 & 57186 & 3 & 0.0231091142569557 & 0.0023146271601249 & 5.95103237660249e-07 \\
        steepest & grippo\_bisection\_goldstein & 5000 & 85869 & 10000 & 0.0408482760313403 & 0.00406451433213122 & 5.81009417802514e-06 \\
\end{tabular}}
\caption{powell}
\label{table:powell}
\end{table}

\begin{table}[h!]
\resizebox{1.2\textwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}
        method & step size & iterations & $n_{f\_eval}$ & $n_{fgrad\_eval}$ &error x1 & error x2 & error fvalue \\ \hline
newton & backtracking\_armijo & 5000 & 254519 & 15000 & 0.974756655623815 & 0.931771030925836 & 1.41545028314515 \\
        newton & wolfe\_strong & 5000 & 59142 & 19653 & 3.33066907387547e-16 & 9.99200722162641e-16 & 1.10933564796705e-31 \\
        newton & bisection\_wolfe\_weak & 30 & 98 & 128 & 0 & 0 & 0 \\
        newton & bisection\_goldstein & 30 & 145 & 89 & 0 & 0 & 0 \\
        newton & hanger\_zhang\_backtracking\_armijo & 9 & 19 & 26 & 0 & 0 & 0 \\
        newton & hanger\_zhang\_bisection\_wolfe\_weak & 11 & 36 & 47 & 0 & 0 & 0 \\
        newton & hanger\_zhang\_wolfe\_strong & 93 & 217 & 3 & 0 & 0 & 0 \\
        newton & hanger\_zhang\_bisection\_goldstein & 11 & 45 & 32 & 0 & 0 & 0 \\
        newton & grippo\_backtracking\_armijo & 9 & 19 & 26 & 0 & 0 & 0 \\
        newton & grippo\_bisection\_wolfe\_weak & 11 & 36 & 47 & 0 & 0 & 0 \\
        newton & grippo\_wolfe\_strong & 93 & 217 & 3 & 0 & 0 & 0 \\
        newton & grippo\_bisection\_goldstein & 11 & 45 & 32 & 0 & 0 & 0 \\
        steepest & backtracking\_armijo & 5000 & 74285 & 10000 & 0.0274393140902852 & 0.0802063102887479 & 0.000754515079695581 \\
        steepest & wolfe\_strong & 5000 & 57791 & 19825 & 0.0301495000526828 & 0.0862421726233629 & 0.00113602375979256 \\
        steepest & bisection\_wolfe\_weak & 5000 & 77879 & 77878 & 0.623712401645518 & 3.28146607960412 & 0.389058449284173 \\
        steepest & bisection\_goldstein & 5000 & 115781 & 10000 & 0.0230666987517512 & 0.0676637553088381 & 0.000532299202237302 \\
        steepest & hanger\_zhang\_backtracking\_armijo & 5000 & 54767 & 10000 & 0.643210458686731 & 1.11031314673264 & 2.83896586565067 \\
        steepest & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 48467 & 48466 & 0.693394222821671 & 0.880856220902563 & 1.29657768062535 \\
        steepest & hanger\_zhang\_wolfe\_strong & 5000 & 38467 & 20000 & 0.693394222821671 & 0.880856220902563 & 1.29657768062535 \\
        steepest & hanger\_zhang\_bisection\_goldstein & 5000 & 92511 & 10000 & 0.224881619323091 & 0.472414117934272 & 0.433586267876597 \\
        steepest & grippo\_backtracking\_armijo & 5000 & 72833 & 10000 & 0.0315507390721171 & 0.0919329120477395 & 0.00100100152525108 \\
        steepest & grippo\_bisection\_wolfe\_weak & 5000 & 60527 & 60526 & 0.0332236359452328 & 0.0963009433319917 & 0.00110471642515406 \\
        steepest & grippo\_wolfe\_strong & 5000 & 52330 & 20000 & 0.0428578921123078 & 0.118707014017743 & 0.00380370979666056 \\
        steepest & grippo\_bisection\_goldstein & 5000 & 113443 & 10000 & 0.0286858815416886 & 0.0834445284855161 & 0.000825704948049781 \\
\end{tabular}}
\caption{cube}
\label{table:cube}
\end{table}

\begin{table}[h!]
\resizebox{1.2\textwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}
        method & step size & iterations & $n_{f\_eval}$ & $n_{fgrad\_eval}$ &error x1 & error x2 & error fvalue \\ \hline
newton & backtracking\_armijo & 7 & 15 & 20 & 1.37672434155201e-16 & 2.38962586983152e-15 & 0 \\
        newton & wolfe\_strong & 43 & 95 & 3 & 1.45650487227625e-15 & 1.38632595200928e-15 & 0 \\
        newton & bisection\_wolfe\_weak & 7 & 20 & 27 & 1.08615071922884e-15 & 2.05907789263158e-15 & 0 \\
        newton & bisection\_goldstein & 6 & 25 & 17 & 5.90446198869167e-16 & 2.98962041662086e-16 & 0 \\
        newton & hanger\_zhang\_backtracking\_armijo & 7 & 15 & 20 & 1.37672434155201e-16 & 2.38962586983152e-15 & 0 \\
        newton & hanger\_zhang\_bisection\_wolfe\_weak & 7 & 20 & 27 & 1.08615071922884e-15 & 2.05907789263158e-15 & 0 \\
        newton & hanger\_zhang\_wolfe\_strong & 43 & 95 & 3 & 1.45650487227625e-15 & 1.38632595200928e-15 & 0 \\
        newton & hanger\_zhang\_bisection\_goldstein & 6 & 25 & 17 & 5.90446198869167e-16 & 2.98962041662086e-16 & 0 \\
        newton & grippo\_backtracking\_armijo & 7 & 15 & 20 & 1.37672434155201e-16 & 2.38962586983152e-15 & 0 \\
        newton & grippo\_bisection\_wolfe\_weak & 7 & 20 & 27 & 1.08615071922884e-15 & 2.05907789263158e-15 & 0 \\
        newton & grippo\_wolfe\_strong & 43 & 95 & 3 & 1.45650487227625e-15 & 1.38632595200928e-15 & 0 \\
        newton & grippo\_bisection\_goldstein & 6 & 25 & 17 & 5.90446198869167e-16 & 2.98962041662086e-16 & 0 \\
        steepest & backtracking\_armijo & 21 & 60 & 41 & 1.68097233232985e-15 & 2.4167869273007e-15 & 0 \\
        steepest & wolfe\_strong & 8 & 15 & 2 & 1.18959956745727e-15 & 1.80155910397182e-15 & 0 \\
        steepest & bisection\_wolfe\_weak & 7 & 23 & 23 & 6.99193385517813e-16 & 7.88087428424387e-16 & 0 \\
        steepest & bisection\_goldstein & 6 & 29 & 11 & 1.72903242167173e-15 & 5.59213856069818e-16 & 0 \\
        steepest & hanger\_zhang\_backtracking\_armijo & 5000 & 10001 & 10000 & 0.00164889450606435 & 5.52008518744069e-05 & 3.44380728570134e-06 \\
        steepest & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 15001 & 15000 & 0.00164889450606435 & 5.52008518744069e-05 & 3.44380728570134e-06 \\
        steepest & hanger\_zhang\_wolfe\_strong & 8 & 15 & 2 & 1.18959956745727e-15 & 1.80155910397182e-15 & 0 \\
        steepest & hanger\_zhang\_bisection\_goldstein & 5000 & 20001 & 10000 & 0.00164889450606435 & 5.52008518744069e-05 & 3.44380728570134e-06 \\
        steepest & grippo\_backtracking\_armijo & 211 & 440 & 421 & 2.15839016977863e-15 & 1.47975262882406e-15 & 0 \\
        steepest & grippo\_bisection\_wolfe\_weak & 5000 & 15001 & 15000 & 0.00164889450606435 & 5.52008518744069e-05 & 3.44380728570134e-06 \\
        steepest & grippo\_wolfe\_strong & 8 & 15 & 2 & 1.18959956745727e-15 & 1.80155910397182e-15 & 0 \\
        steepest & grippo\_bisection\_goldstein & 46 & 189 & 91 & 1.92895613178363e-16 & 1.51468484208526e-15 & 0 \\
\end{tabular}}
\caption{trig(20)}
\label{table:trig(20)}
\end{table}

% \begin{table}[h!]
% \resizebox{1.2\textwidth}{!}{
% \begin{tabular}{|l|l|l|l|l|l|l|l|}
%         method & step size & iterations & $n_{f\_eval}$ & $n_{fgrad\_eval}$ &error x1 & error x2 & error fvalue \\ \hline
% newton & backtracking\_armijo & 1.0000e+02 & 1.0980e+03 & 3.0000e+02 & 4.6300e-03 & 1.0165e-03 & 7.0795e+03 \\
%         newton & bisection\_wolfe\_weak & 1.0000e+02 & 2.1880e+03 & 2.2880e+03 & 3.4366e-03 & 3.1488e-03 & 7.0791e+03 \\
%         newton & bisection\_goldstein & 1.0000e+02 & 4.1760e+03 & 3.0000e+02 & 3.4366e-03 & 3.1488e-03 & 7.0791e+03 \\
%         newton & hanger\_zhang\_backtracking\_armijo & 1.0000e+02 & 1.0890e+03 & 3.0000e+02 & 5.4620e-03 & 4.7018e-04 & 7.0797e+03 \\
%         newton & hanger\_zhang\_bisection\_wolfe\_weak & 1.0000e+02 & 2.1370e+03 & 2.2380e+03 & 4.3945e-03 & 1.4372e-03 & 7.0794e+03 \\
%         newton & hanger\_zhang\_bisection\_goldstein & 1.0000e+02 & 4.0750e+03 & 3.0000e+02 & 4.3945e-03 & 1.4372e-03 & 7.0794e+03 \\
%         newton & grippo\_backtracking\_armijo & 1.0000e+02 & 1.0320e+03 & 3.0000e+02 & 6.6162e-03 & 2.5325e-03 & 7.0800e+03 \\
%         newton & grippo\_bisection\_wolfe\_weak & 1.0000e+02 & 2.1370e+03 & 2.2880e+03 & 5.6649e-03 & 8.3273e-04 & 7.0798e+03 \\
%         newton & grippo\_bisection\_goldstein & 1.0000e+02 & 3.9710e+03 & 3.0000e+02 & 5.6737e-03 & 8.4844e-04 & 7.0798e+03 \\
%         steepest & backtracking\_armijo & 1.0000e+02 & 6.9000e+02 & 2.0000e+02 & 1.7097e-02 & 3.1216e+00 & 3.6548e+03 \\
%         steepest & bisection\_wolfe\_weak & 1.0000e+02 & 7.9000e+02 & 7.9000e+02 & 6.2900e+00 & 3.1216e+00 & 3.6548e+03 \\
%         steepest & bisection\_goldstein & 1.0000e+02 & 1.3720e+03 & 2.0000e+02 & 6.3005e+00 & 1.5688e+01 & 3.6548e+03 \\
%         steepest & hanger\_zhang\_backtracking\_armijo & 1.0000e+02 & 5.9800e+02 & 2.0000e+02 & 2.9846e+01 & 1.6259e+01 & 3.9271e+03 \\
%         steepest & hanger\_zhang\_bisection\_wolfe\_weak & 1.0000e+02 & 4.7100e+02 & 4.7200e+02 & 1.1337e+02 & 2.6153e+02 & 4.5217e+03 \\
%         steepest & hanger\_zhang\_bisection\_goldstein & 1.0000e+02 & 1.1930e+03 & 2.0000e+02 & 4.8945e+01 & 3.7330e+00 & 3.9152e+03 \\
%         steepest & grippo\_backtracking\_armijo & 1.0000e+02 & 3.2300e+02 & 2.0000e+02 & 8.0343e+01 & 2.2307e+01 & 5.3318e+03 \\
%         steepest & grippo\_bisection\_wolfe\_weak & 1.0000e+02 & 2.5100e+02 & 3.0200e+02 & 5.2438e+02 & 1.9875e+02 & 5.5293e+03 \\
%         steepest & grippo\_bisection\_goldstein & 1.0000e+02 & 7.0100e+02 & 2.0000e+02 & 7.4617e+01 & 2.6312e+02 & 5.4972e+03 \\
% \end{tabular}}
% \caption{trig(60) needs update}
% \label{table:trig(60)}
% \end{table}

\clearpage

\subsection{}

Program the steepest descent and Newton algorithms using the a) backtracking line search with armijo or b) wolfe weak condition. c) the wolfe strong condition and d) without any condition. Use them to minimize the following functions:

\begin{align*}
    f_1(x,y) &= 100 (y-x^2)^2 + (1-x)^2, \\ &\quad [x_0,y_0] = [-1.8,-1.8], \quad f_{min}(1,1)=0  \\
    f_2(x,y) &= x^2 + 4y^2 + 2xy, \\ & \quad [x_0,y_0] [-3,-3], \quad f_{min}(0,0) = 0 \\
    f_3(x,y) &= (x+2y-7)^2 + (2x+y-5)^2, \\ & \quad [x_0,y_0] = [-9.5,9.5], \quad f_{min}(1,3) = 0 \\
    f_4(x,y) &= 5x^4 + 6y^4 - 6x^2 + 2xy + 5y^2 + 15x -7y + 13, \\ & \quad [x_0,y_0] = [1.9,-1.9], \quad f_{min}(-1.1515,0.5455) = -6.4931 \\ 
    f_5(x,y) &= (x^2)^{y^2+1} + (y^2)^{x^2+1},\\ & \quad [x_0,y_0] = [-1.5,1.25], \quad f_{min}(0,0) = 0 \\
    f_6(x,y,z) &= x^2 + y^3 - (z^4)^2 + (2xyz)^2 + (2xy-3yz+xz)^2, \\ & \quad [x_0,y_0,z_0] = [10,10,10], \quad f_{min}(0.0048605831,0.0016994507,X) = 0 \\
    f_7(x,y,z) &= x^2 + (y + y^2) + (-1 + e^z)^2, \\ & \quad [x_0,y_0,z_0] = [2,3,-8], \quad f_{min}(3.02442e-08,-1,2.40687e-08) = 0 \\
    f_8(x,y,z,k) &= (x-1)^2 + (x-\sqrt{y})^2 + (y-\sqrt{z})^2 + (z-\sqrt{k})^2, \\ & \quad [x_0,y_0,z_0,k_0] = [0.1,0.1,0.1,0.1], \quad f_{min}(0.999993,0.999983,0.999964,0.999912) = 1.13719^{-10} \\
\end{align*}

For the analysis we have created the tables under \ref{simulation1}. For the plots you can check \ref{plots}.


% Problems listed on Chapter 3 of \cite{nocedal1999numerical}.
\subsubsection{Numerical results}
\label{simulation1}



The configuration for the methods is as follows:

\textbf{Wolfe strong}

\begin{align*}
a &= 1 \\
rho &= 2 \\
c1 &= 1e-4 \\
c2 &= 0.9 \\
eps &= 1e-16 \\ 
max\_iters &= 5000 \\ 
max\_iters\_step\_size &= 50 \\
max\_iters\_zoom &= 10 \\
\end{align*}

\textbf{Non wolfe methods}

\begin{align*}
a &= 1 \\
rho &= 0.6 \\
c &= 0.1 \\
eps &= 1e-16 \\ 
max\_iters &= 5000 \\ 
max\_iters\_step\_size &= 50 \\
\end{align*}

For grippo, we have added the $memory\_limit = 10$ parameter.

\begin{table}[h!]
\resizebox{1.2\textwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}
        method & step size & iterations & $n_{f\_eval}$ & $n_{fgrad\_eval}$ &error x1 & error x2 & error fvalue \\ \hline
newton & none & 7 & 7 & 14 & 0 & 0 & 0 \\
        newton & backtracking\_armijo & 29 & 76 & 86 & 0 & 0 & 0 \\
        newton & wolfe\_strong & 5000 & 59201 & 19678 & 5.55111512312578e-16 & 1.11022302462516e-15 & 3.08148791101958e-31 \\
        newton & bisection\_wolfe\_weak & 29 & 93 & 122 & 0 & 0 & 0 \\
        newton & bisection\_goldstein & 28 & 127 & 83 & 0 & 0 & 0 \\
        newton & hanger\_zhang\_backtracking\_armijo & 10 & 20 & 29 & 0 & 0 & 0 \\
        newton & hanger\_zhang\_bisection\_wolfe\_weak & 10 & 29 & 39 & 0 & 0 & 0 \\
        newton & hanger\_zhang\_wolfe\_strong & 85 & 180 & 3 & 0 & 0 & 0 \\
        newton & hanger\_zhang\_bisection\_goldstein & 10 & 39 & 29 & 0 & 0 & 0 \\
        newton & grippo\_backtracking\_armijo & 10 & 20 & 29 & 0 & 0 & 0 \\
        newton & grippo\_bisection\_wolfe\_weak & 10 & 29 & 39 & 0 & 0 & 0 \\
        newton & grippo\_wolfe\_strong & 85 & 180 & 3 & 0 & 0 & 0 \\
        newton & grippo\_bisection\_goldstein & 10 & 39 & 29 & 0 & 0 & 0 \\
        steepest & none & 10 & 39 & 29 & inf & inf & inf \\
        steepest & backtracking\_armijo & 5000 & 69953 & 10000 & 0.000231853657516545 & 0.000465659507062566 & 5.41585013010586e-08 \\
        steepest & wolfe\_strong & 5000 & 53706 & 20000 & 0.00182500974970823 & 0.00681981112059682 & 0.0010102011620911 \\
        steepest & bisection\_wolfe\_weak & 5000 & 59076 & 59075 & 0.00217214517391573 & 0.00435307813413655 & 4.73645586276291e-06 \\
        steepest & bisection\_goldstein & 5000 & 108535 & 10000 & 0.00147851091350937 & 0.00296432049244699 & 2.19499039880236e-06 \\
        steepest & hanger\_zhang\_backtracking\_armijo & 5000 & 59124 & 10000 & 0.978417699202881 & 0.717767377990892 & 8.89655563451037 \\
        steepest & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 77671 & 77670 & 3.12346213405168 & 15.8923036966325 & 10.9800542225191 \\
        steepest & hanger\_zhang\_wolfe\_strong & 5000 & 77671 & 77670 & inf & inf & inf \\
        steepest & hanger\_zhang\_bisection\_goldstein & 5000 & 115761 & 10000 & 0.916843811761581 & 0.790158011592207 & 4.95854080020614 \\
        steepest & grippo\_backtracking\_armijo & 5000 & 77754 & 10000 & 0.292024103878915 & 0.666216248943581 & 0.0862453096760649 \\
        steepest & grippo\_bisection\_wolfe\_weak & 5000 & 75152 & 75151 & 2.46702946497995 & 11.0251371515968 & 6.08858066021404 \\
        steepest & grippo\_wolfe\_strong & 5000 & 75152 & 75151 & inf & inf & inf \\
        steepest & grippo\_bisection\_goldstein & 5000 & 127895 & 10000 & 1.01566086461543 & 3.06146355134602 & 1.03177010280615 \\
\end{tabular}}
\caption{f1}
\label{table:f1}
\end{table}

\clearpage

\textbf{Question}
Why using \verb|steepest descent - Hanger Zhang| has bad performance instead of the newton equivalent?

\textbf{Answer}
The Hanger Zhang method is being tested for second order derivatives methods, and there isn't any analysis for the steepest descent method. We could also epxeriment with the degree of non-monotonicity (here it is pure nonmonotone ($\eta_k = 1$)).

\textbf{Question}
Why \verb|steepest - grippo/HangerZhang - wolfe - strong| doesn't converge?

\textbf{Answer}
There is a maximum number of iterations when searching alpha values to satisfy the wole strong conditions. If the number of iterations is reached, then we still return the latest alpha value. But, the last one hasn't satisfy the conditions, thus divergence is possible. Carefully tuning particular cases, could resolve these issues.

\begin{table}[h!]
\resizebox{1.2\textwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}
        method & step size & iterations & $n_{f\_eval}$ & $n_{fgrad\_eval}$ &error x1 & error x2 & error fvalue \\ \hline
newton & none & 3 & 3 & 3 & 0 & 1.97215226305253e-31 & 1.55575381946529e-61 \\
        newton & backtracking\_armijo & 3 & 5 & 5 & 0 & 1.97215226305253e-31 & 1.55575381946529e-61 \\
        newton & wolfe\_strong & 60 & 119 & 2 & 5.20417042793058e-18 & 5.2041704279303e-18 & 1.89583728900615e-34 \\
        newton & bisection\_wolfe\_weak & 3 & 7 & 7 & 0 & 1.97215226305253e-31 & 1.55575381946529e-61 \\
        newton & bisection\_goldstein & 3 & 9 & 5 & 0 & 1.97215226305253e-31 & 1.55575381946529e-61 \\
        newton & hanger\_zhang\_backtracking\_armijo & 3 & 5 & 5 & 0 & 1.97215226305253e-31 & 1.55575381946529e-61 \\
        newton & hanger\_zhang\_bisection\_wolfe\_weak & 3 & 7 & 7 & 0 & 1.97215226305253e-31 & 1.55575381946529e-61 \\
        newton & hanger\_zhang\_wolfe\_strong & 60 & 119 & 2 & 5.20417042793058e-18 & 5.2041704279303e-18 & 1.89583728900615e-34 \\
        newton & hanger\_zhang\_bisection\_goldstein & 3 & 9 & 5 & 0 & 1.97215226305253e-31 & 1.55575381946529e-61 \\
        newton & grippo\_backtracking\_armijo & 3 & 5 & 5 & 0 & 1.97215226305253e-31 & 1.55575381946529e-61 \\
        newton & grippo\_bisection\_wolfe\_weak & 3 & 7 & 7 & 0 & 1.97215226305253e-31 & 1.55575381946529e-61 \\
        newton & grippo\_wolfe\_strong & 60 & 119 & 2 & 5.20417042793058e-18 & 5.2041704279303e-18 & 1.89583728900615e-34 \\
        newton & grippo\_bisection\_goldstein & 3 & 9 & 5 & 0 & 1.97215226305253e-31 & 1.55575381946529e-61 \\
        steepest & none & 3 & 9 & 5 & inf & inf & inf \\
        steepest & backtracking\_armijo & 100 & 498 & 199 & 2.70673866579265e-17 & 1.23492342742777e-17 & 6.74134771071291e-34 \\
        steepest & wolfe\_strong & 62 & 431 & 6 & 1.70684847756752e-17 & 7.36851893081964e-18 & 2.56974551092906e-34 \\
        steepest & bisection\_wolfe\_weak & 59 & 293 & 293 & 3.12250225675825e-17 & 7.80625564189563e-18 & 7.31251525759529e-34 \\
        steepest & bisection\_goldstein & 59 & 469 & 117 & 3.12250225675825e-17 & 7.80625564189563e-18 & 7.31251525759529e-34 \\
        steepest & hanger\_zhang\_backtracking\_armijo & 5000 & 24151 & 10000 & 0.044148265854443 & 0.14581181691217 & 0.0998680908983826 \\
        steepest & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 24153 & 24152 & 0.0899068500296963 & 0.296942153943305 & 0.414176080240371 \\
        steepest & hanger\_zhang\_wolfe\_strong & 60 & 375 & 7 & 3.86210908546545e-17 & 1.27842847880622e-17 & 1.15785436034954e-33 \\
        steepest & hanger\_zhang\_bisection\_goldstein & 5000 & 38303 & 10000 & 0.0390428179613046 & 0.128949667991002 & 0.0781055259614048 \\
        steepest & grippo\_backtracking\_armijo & 1611 & 7820 & 3221 & 3.2192681707706e-18 & 1.06325204857472e-17 & 5.31023524624337e-34 \\
        steepest & grippo\_bisection\_wolfe\_weak & 3533 & 17020 & 17020 & 3.32746491293465e-18 & 1.09898700498486e-17 & 5.6731781157421e-34 \\
        steepest & grippo\_wolfe\_strong & 60 & 375 & 7 & 3.86210908546545e-17 & 1.27842847880622e-17 & 1.15785436034954e-33 \\
        steepest & grippo\_bisection\_goldstein & 1462 & 11107 & 2923 & 3.31272855220176e-18 & 1.09411991566311e-17 & 5.62303972083832e-34 \\

\end{tabular}}
\caption{f2}
\label{table:f2}
\end{table}

\begin{table}[h!]
\resizebox{1.2\textwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}
        method & step size & iterations & $n_{f\_eval}$ & $n_{fgrad\_eval}$ &error x1 & error x2 & error fvalue \\ \hline
newton & none & 3 & 3 & 3 & 7.7715611723761e-16 & 8.88178419700125e-16 & 1.57772181044202e-30 \\
        newton & backtracking\_armijo & 3 & 5 & 5 & 7.7715611723761e-16 & 8.88178419700125e-16 & 1.57772181044202e-30 \\
        newton & wolfe\_strong & 56 & 111 & 2 & 0 & 4.44089209850063e-16 & 7.88860905221012e-31 \\
        newton & bisection\_wolfe\_weak & 3 & 7 & 7 & 7.7715611723761e-16 & 8.88178419700125e-16 & 1.57772181044202e-30 \\
        newton & bisection\_goldstein & 3 & 9 & 5 & 7.7715611723761e-16 & 8.88178419700125e-16 & 1.57772181044202e-30 \\
        newton & hanger\_zhang\_backtracking\_armijo & 3 & 5 & 5 & 7.7715611723761e-16 & 8.88178419700125e-16 & 1.57772181044202e-30 \\
        newton & hanger\_zhang\_bisection\_wolfe\_weak & 3 & 7 & 7 & 7.7715611723761e-16 & 8.88178419700125e-16 & 1.57772181044202e-30 \\
        newton & hanger\_zhang\_wolfe\_strong & 56 & 111 & 2 & 0 & 4.44089209850063e-16 & 7.88860905221012e-31 \\
        newton & hanger\_zhang\_bisection\_goldstein & 3 & 9 & 5 & 7.7715611723761e-16 & 8.88178419700125e-16 & 1.57772181044202e-30 \\
        newton & grippo\_backtracking\_armijo & 3 & 5 & 5 & 7.7715611723761e-16 & 8.88178419700125e-16 & 1.57772181044202e-30 \\
        newton & grippo\_bisection\_wolfe\_weak & 3 & 7 & 7 & 7.7715611723761e-16 & 8.88178419700125e-16 & 1.57772181044202e-30 \\
        newton & grippo\_wolfe\_strong & 56 & 111 & 2 & 0 & 4.44089209850063e-16 & 7.88860905221012e-31 \\
        newton & grippo\_bisection\_goldstein & 3 & 9 & 5 & 7.7715611723761e-16 & 8.88178419700125e-16 & 1.57772181044202e-30 \\
        steepest & none & 3 & 9 & 5 & inf & inf & inf \\
        steepest & backtracking\_armijo & 145 & 930 & 289 & 6.66133814775094e-16 & 8.88178419700125e-16 & 7.88860905221012e-31 \\
        steepest & wolfe\_strong & 36 & 342 & 31 & 0 & 4.44089209850063e-16 & 7.88860905221012e-31 \\
        steepest & bisection\_wolfe\_weak & 86 & 514 & 514 & 1.77635683940025e-15 & 1.77635683940025e-15 & 6.31088724176809e-30 \\
        steepest & bisection\_goldstein & 22 & 247 & 43 & 0 & 0 & 0 \\
        steepest & hanger\_zhang\_backtracking\_armijo & 5000 & 30978 & 10000 & 0.4558675606856 & 0.4558675606856 & 3.7406741919379 \\
        steepest & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 27531 & 27530 & 0.11152570336948 & 0.111525703369479 & 0.223883685217029 \\
        steepest & hanger\_zhang\_wolfe\_strong & 5000 & 26410 & 24 & 0.076798441453831 & 0.0767984414538301 & 0.106164010975274 \\
        steepest & hanger\_zhang\_bisection\_goldstein & 5000 & 45057 & 10000 & 0.713764501564678 & 0.713764501564678 & 9.17027574648971 \\
        steepest & grippo\_backtracking\_armijo & 4400 & 27037 & 8799 & 2.22044604925031e-16 & 0 & 0 \\
        steepest & grippo\_bisection\_wolfe\_weak & 2630 & 15037 & 15037 & 2.22044604925031e-16 & 0 & 0 \\
        steepest & grippo\_wolfe\_strong & 415 & 1926 & 8 & 2.22044604925031e-16 & 0 & 0 \\
        steepest & grippo\_bisection\_goldstein & 2490 & 23523 & 4979 & 2.22044604925031e-16 & 0 & 0 \\

\end{tabular}}
\caption{f3}
\label{table:f3}
\end{table}

\begin{table}[h!]
\resizebox{1.2\textwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}
        method & step size & iterations & $n_{f\_eval}$ & $n_{fgrad\_eval}$ &error x1 & error x2 & error fvalue \\ \hline
newton & none & 5000 & 5001 & 10000 & 0.00944507163076302 & 0.00212751879491324 & 0.00301893549106502 \\
        newton & backtracking\_armijo & 5000 & 254854 & 15000 & 1.40217627348875 & 0.749386153253358 & 24.4391562019666 \\
        newton & wolfe\_strong & 5000 & 59580 & 19789 & 0.00944507163055874 & 0.00212751879489237 & 0.00301893549106858 \\
        newton & bisection\_wolfe\_weak & 5000 & 259854 & 264853 & 1.40217621083734 & 0.749386170778393 & 24.4391556096527 \\
        newton & bisection\_goldstein & 5000 & 509707 & 15000 & 1.40217621083734 & 0.749386170778393 & 24.4391556096527 \\
        newton & hanger\_zhang\_backtracking\_armijo & 5000 & 10005 & 15000 & 0.00944507163076302 & 0.00212751879491324 & 0.00301893549106502 \\
        newton & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 17495 & 22494 & 0.00944507163076302 & 0.00212751879491324 & 0.00301893549106502 \\
        newton & hanger\_zhang\_wolfe\_strong & 5000 & 252257 & 1 & 0.00944507163076302 & 0.00212751879491324 & 0.00301893549106502 \\
        newton & hanger\_zhang\_bisection\_goldstein & 5000 & 20007 & 15000 & 0.00944507163076302 & 0.00212751879491324 & 0.00301893549106502 \\
        newton & grippo\_backtracking\_armijo & 5000 & 10003 & 15000 & 0.00944507163076302 & 0.00212751879491324 & 0.00301893549106502 \\
        newton & grippo\_bisection\_wolfe\_weak & 5000 & 17495 & 22494 & 0.00944507163076302 & 0.00212751879491324 & 0.00301893549106502 \\
        newton & grippo\_wolfe\_strong & 5000 & 252218 & 1 & 0.00944507163076302 & 0.00212751879491324 & 0.00301893549106502 \\
        newton & grippo\_bisection\_goldstein & 5000 & 20005 & 15000 & 0.00944507163076302 & 0.00212751879491324 & 0.00301893549106502 \\
        steepest & none & 5000 & 20005 & 15000 & inf & inf & inf \\
        steepest & backtracking\_armijo & 5000 & 208797 & 10000 & 0.00944507059391952 & 0.00212751885374851 & 0.00301893549107213 \\
        steepest & wolfe\_strong & 5000 & 59948 & 23 & 0.00944507333052891 & 0.00212751869797989 & 0.00301893549106858 \\
        steepest & bisection\_wolfe\_weak & 5000 & 257138 & 257137 & 0.00944507172751208 & 0.00212751878940254 & 0.00301893549107213 \\
        steepest & bisection\_goldstein & 5000 & 336321 & 10000 & 0.0094450675138269 & 0.00212751902941188 & 0.00301893549107213 \\
        steepest & hanger\_zhang\_backtracking\_armijo & 5000 & 43406 & 10000 & 0.0723637957299208 & 0.00876210112939202 & 0.233200749629811 \\
        steepest & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 39902 & 39901 & 0.110247766267134 & 0.012056320259421 & 0.515693200985845 \\
        steepest & hanger\_zhang\_wolfe\_strong & 5000 & 29945 & 20016 & 0.169951474669254 & 0.00500335112232564 & 0.762411106606868 \\
        steepest & hanger\_zhang\_bisection\_goldstein & 5000 & 69417 & 10000 & 0.0804348386753735 & 0.00860850633843635 & 0.283336619645704 \\
        steepest & grippo\_backtracking\_armijo & 5000 & 81295 & 10000 & 0.0094450832818378 & 0.00212751813128087 & 0.00301893549106858 \\
        steepest & grippo\_bisection\_wolfe\_weak & 5000 & 38795 & 38794 & 0.00944507072750889 & 0.00212751884636175 & 0.00301893549106502 \\
        steepest & grippo\_wolfe\_strong & 5000 & 56788 & 9 & 0.00944507336164002 & 0.00212751869632233 & 0.00301893549106858 \\
        steepest & grippo\_bisection\_goldstein & 5000 & 64507 & 10000 & 0.00944555839933625 & 0.00212749106912524 & 0.003018935483178 \\
\end{tabular}}
\caption{f4}
\label{table:f4}
\end{table}

\begin{table}[h!]
\resizebox{1.2\textwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}
        method & step size & iterations & $n_{f\_eval}$ & $n_{fgrad\_eval}$ &error x1 & error x2 & error fvalue \\ \hline
newton & none & 5000 & 5001 & 10000 & inf & inf & inf \\
        newton & backtracking\_armijo & 9 & 18 & 26 & 1.0097419586829e-28 & 1.0097419586829e-28 & 2.03915764624954e-56 \\
        newton & wolfe\_strong & 79 & 364 & 3 & 4.39949904840856e-17 & 4.42154583004284e-18 & 1.95510925522195e-33 \\
        newton & bisection\_wolfe\_weak & 9 & 26 & 35 & 1.0097419586829e-28 & 2.01948391736579e-28 & 5.09789411562385e-56 \\
        newton & bisection\_goldstein & 9 & 35 & 26 & 1.0097419586829e-28 & 2.01948391736579e-28 & 5.09789411562385e-56 \\
        newton & hanger\_zhang\_backtracking\_armijo & 9 & 18 & 26 & 1.0097419586829e-28 & 1.0097419586829e-28 & 2.03915764624954e-56 \\
        newton & hanger\_zhang\_bisection\_wolfe\_weak & 9 & 26 & 35 & 1.0097419586829e-28 & 2.01948391736579e-28 & 5.09789411562385e-56 \\
        newton & hanger\_zhang\_wolfe\_strong & 60 & 140 & 3 & 3.64609268262052e-17 & 6.55195413889377e-18 & 1.37232728806406e-33 \\
        newton & hanger\_zhang\_bisection\_goldstein & 9 & 35 & 26 & 1.0097419586829e-28 & 2.01948391736579e-28 & 5.09789411562385e-56 \\
        newton & grippo\_backtracking\_armijo & 9 & 18 & 26 & 1.0097419586829e-28 & 1.0097419586829e-28 & 2.03915764624954e-56 \\
        newton & grippo\_bisection\_wolfe\_weak & 9 & 26 & 35 & 1.0097419586829e-28 & 2.01948391736579e-28 & 5.09789411562385e-56 \\
        newton & grippo\_wolfe\_strong & 61 & 142 & 3 & 3.89363641597854e-17 & 2.64867350409597e-18 & 1.52305592531472e-33 \\
        newton & grippo\_bisection\_goldstein & 9 & 35 & 26 & 1.0097419586829e-28 & 2.01948391736579e-28 & 5.09789411562385e-56 \\
        steepest & none & 9 & 35 & 26 & inf & inf & inf \\
        steepest & backtracking\_armijo & 25 & 78 & 49 & 6.85627032245252e-18 & 3.91826085607981e-17 & 1.58228525636327e-33 \\
        steepest & wolfe\_strong & 8 & 40 & 3 & 3.95520219608251e-18 & 2.87545235394022e-19 & 1.57263066742937e-35 \\
        steepest & bisection\_wolfe\_weak & 169 & 516 & 515 & 1.553548587951155e-23 & 0 & 2.413513215125028e-46 \\
        steepest & bisection\_goldstein & 5 & 39 & 10 & 0 & 0 & 0 \\
        steepest & hanger\_zhang\_backtracking\_armijo & 5000 & 10008 & 10000 & 5.15377650230993e-147 & 0.0724316975798939 & 0.00524635081430521 \\
        steepest & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 15010 & 15009 & 0.211905875131239 & 1.80829961496735e-10 & 0.0449040999151361 \\
        steepest & hanger\_zhang\_wolfe\_strong & 8 & 40 & 3 & 3.95520219608251e-18 & 2.87545235394022e-19 & 1.57263066742937e-35 \\
        steepest & hanger\_zhang\_bisection\_goldstein & 5000 & 20013 & 10000 & 3.32946308142177e-08 & 0.00434180915679895 & 1.88513067551708e-05 \\
        steepest & grippo\_backtracking\_armijo & 261 & 550 & 521 & 9.55211620389891e-19 & 3.24481979382993e-17 & 1.05379797868278e-33 \\
        steepest & grippo\_bisection\_wolfe\_weak & 169 & 516 & 515 & 1.553548587951155e-23 & 0 & 2.413513215125028e-46 \\
        steepest & grippo\_wolfe\_strong & 8 & 40 & 3 & 3.95520219608251e-18 & 2.87545235394022e-19 & 1.57263066742937e-35 \\
        steepest & grippo\_bisection\_goldstein & 5 & 39 & 10 & 0 & 0 & 0 \\
\end{tabular}}
\caption{f5}
\label{table:f5}
\end{table}

\begin{table}[h!]
\resizebox{1.2\textwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}
        method & step size & iterations & $n_{f\_eval}$ & $n_{fgrad\_eval}$ &error x1 & error x2 & error fvalue \\ \hline
newton & none & 57 & 57 & 114 & 0.00486057385712604 & 0.00126211245324357 & 6.99689963833515e-21 \\
        newton & backtracking\_armijo & 5000 & 254413 & 15000 & 0.893506375012991 & 1.27695478817845 & 37.0167052250215 \\
        newton & wolfe\_strong & 281 & 561 & 3 & 0.00485228217352344 & 0.00169667840056468 & 1.79066786078225e-26 \\
        newton & bisection\_wolfe\_weak & 5000 & 259413 & 264412 & 0.893506487819556 & 1.27695453250971 & 37.0167026015569 \\
        newton & bisection\_goldstein & 5000 & 508825 & 15000 & 0.893506487819556 & 1.27695453250971 & 37.0167026015569 \\
        newton & hanger\_zhang\_backtracking\_armijo & 57 & 113 & 170 & 0.00486057385712604 & 0.00126211245324357 & 6.99689963833515e-21 \\
        newton & hanger\_zhang\_bisection\_wolfe\_weak & 57 & 169 & 226 & 0.00486057385712604 & 0.00126211245324357 & 6.99689963833515e-21 \\
        newton & hanger\_zhang\_wolfe\_strong & 281 & 561 & 3 & 0.00485228217352344 & 0.00169667840056468 & 1.79066786078225e-26 \\
        newton & hanger\_zhang\_bisection\_goldstein & 57 & 225 & 170 & 0.00486057385712604 & 0.00126211245324357 & 6.99689963833515e-21 \\
        newton & grippo\_backtracking\_armijo & 57 & 113 & 170 & 0.00486057385712604 & 0.00126211245324357 & 6.99689963833515e-21 \\
        newton & grippo\_bisection\_wolfe\_weak & 57 & 169 & 226 & 0.00486057385712604 & 0.00126211245324357 & 6.99689963833515e-21 \\
        newton & grippo\_wolfe\_strong & 281 & 561 & 3 & 0.00485228217352344 & 0.00169667840056468 & 1.79066786078225e-26 \\
        newton & grippo\_bisection\_goldstein & 57 & 225 & 170 & 0.00486057385712604 & 0.00126211245324357 & 6.99689963833515e-21 \\
        steepest & none & 57 & 225 & 170 & inf & inf & inf \\
        steepest & backtracking\_armijo & 5000 & 10201 & 10000 & 0.0493461672944513 & 0.0139342912130714 & 1.58369115811853e-07 \\
        steepest & wolfe\_strong & 5000 & 254923 & 1 & nan & nan & nan \\
        steepest & bisection\_wolfe\_weak & 5000 & 32342 & 32341 & 0.00902808107374527 & 0.00315104886219878 & 6.11872358929565e-13 \\
        steepest & bisection\_goldstein & 5000 & 28225 & 10000 & 0.0303715945819052 & 0.00873750603986036 & 1.93099727073731e-08 \\
        steepest & hanger\_zhang\_backtracking\_armijo & 5000 & 17977 & 10000 & 0.0384613861009257 & 0.0109783824493726 & 5.30631639931804e-08 \\
        steepest & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 31185 & 31184 & 0.0156402736424786 & 0.0767542944101401 & 1.49229006031078e-09 \\
        steepest & hanger\_zhang\_wolfe\_strong & 5000 & 254923 & 1 & nan & nan & nan \\
        steepest & hanger\_zhang\_bisection\_goldstein & 5000 & 68621 & 10000 & 0.00648524302003103 & 0.00222683414109805 & 4.77549825745566e-15 \\
        steepest & grippo\_backtracking\_armijo & 5000 & 11820 & 10000 & 0.0399938084786245 & 0.109580141999027 & 4.01131584202259e-08 \\
        steepest & grippo\_bisection\_wolfe\_weak & 5000 & 49245 & 49244 & 0.00486060116460316 & 0.00866604243816793 & 1.24033880517263e-12 \\
        steepest & grippo\_wolfe\_strong & 5000 & 254923 & 1 & nan & nan & nan \\
        steepest & grippo\_bisection\_goldstein & 5000 & 98407 & 10000 & 0.00486074314322908 & 0.00793820207694333 & 8.01460436001753e-13 \\

\end{tabular}}
\caption{f6}
\label{table:f6}
\end{table}

\clearpage

\textbf{Question}
Why \verb|wolfe - strong| doesn't converge?

\textbf{Answer}
TODO

\begin{table}[h!]
\resizebox{1.2\textwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}
        method & step size & iterations & $n_{f\_eval}$ & $n_{fgrad\_eval}$ &error x1 & error x2 & error fvalue \\ \hline
newton & none & 31 & 31 & 62 & 3.02442e-08 & 1 & 0.999999999999998 \\
        newton & backtracking\_armijo & 5000 & 235845 & 15000 & 3.02442e-08 & 1.0000054886393 & 0.999999775079521 \\
        newton & wolfe\_strong & 5000 & 59771 & 19910 & 1.4516654587758e-08 & 1.00000390148057 & 0.999999999549509 \\
        newton & bisection\_wolfe\_weak & 5000 & 259516 & 264515 & 3.02442e-08 & 1.00000548864712 & 0.999999775079201 \\
        newton & bisection\_goldstein & 5000 & 509217 & 15000 & 3.02442e-08 & 1.00000548864712 & 0.999999775079201 \\
        newton & hanger\_zhang\_backtracking\_armijo & 31 & 61 & 92 & 3.02442e-08 & 1 & 0.999999999999998 \\
        newton & hanger\_zhang\_bisection\_wolfe\_weak & 14 & 52 & 66 & 3.02442e-08 & 1 & 0.999999999999998 \\
        newton & hanger\_zhang\_wolfe\_strong & 121 & 1211 & 5 & 3.02441999998298e-08 & 1 & 0.999999999999998 \\
        newton & hanger\_zhang\_bisection\_goldstein & 15 & 83 & 44 & 3.02442e-08 & 1 & 0.999999999999998 \\
        newton & grippo\_backtracking\_armijo & 5000 & 192819 & 15000 & 3.02442e-08 & 1 & 0.999999999989905 \\
        newton & grippo\_bisection\_wolfe\_weak & 14 & 52 & 66 & 3.02442e-08 & 1 & 0.999999999999998 \\
        newton & grippo\_wolfe\_strong & 5000 & 59771 & 19871 & 2.90650317357518e-08 & 1.00000029252758 & 0.999999999950998 \\
        newton & grippo\_bisection\_goldstein & 15 & 83 & 44 & 3.02442e-08 & 1 & 0.999999999999998 \\
        steepest & none & 15 & 83 & 44 & inf & inf & inf \\
        steepest & backtracking\_armijo & 1525 & 3084 & 3049 & 3.02441999996452e-08 & 0 & 1.58063e-15 \\
        steepest & wolfe\_strong & 1509 & 76230 & 2 & 3.02442e-08 & 1 & 1.58063e-15 \\
        steepest & bisection\_wolfe\_weak & 1481 & 4473 & 4473 & 3.02442e-08 & 1 & 1.58063e-15 \\
        steepest & bisection\_goldstein & 1209 & 4915 & 2417 & 3.02442e-08 & 1 & 1.58063e-15 \\
        steepest & hanger\_zhang\_backtracking\_armijo & 5000 & 10040 & 10000 & 5.32439114190643e-05 & 0.00177488766074663 & 2.4324966093065e-05 \\
        steepest & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 15009 & 15008 & 1.4062499697558 & 0.00177612087082302 & 1.97756246347216 \\
        steepest & hanger\_zhang\_wolfe\_strong & 1509 & 76230 & 2 & 3.02442e-08 & 1 & 1.58063e-15 \\
        steepest & hanger\_zhang\_bisection\_goldstein & 5000 & 20045 & 10000 & 3.02442e-08 & 0.00209353477331264 & 2.58799094684486e-05 \\
        steepest & grippo\_backtracking\_armijo & 1769 & 3644 & 3537 & 3.02441999991016e-08 & 0 & 1.58063e-15 \\
        steepest & grippo\_bisection\_wolfe\_weak & 5000 & 15022 & 15021 & 3.02442e-08 & 0.00209279253790684 & 2.55109296748935e-05 \\
        steepest & grippo\_wolfe\_strong & 1510 & 76234 & 2 & 3.02442e-08 & 0 & 1.58063e-15 \\
        steepest & grippo\_bisection\_goldstein & 1566 & 6315 & 3131 & 3.02442e-08 & 1 & 1.58063e-15 \\
\end{tabular}}
\caption{f7}
\label{table:f7}
\end{table}

\begin{table}[h!]
\resizebox{1.2\textwidth}{!}{
\begin{tabular}{|l|l|l|l|l|l|l|l|}
        method & step size & iterations & $n_{f\_eval}$ & $n_{fgrad\_eval}$ &error x1 & error x2 & error fvalue \\ \hline
newton & none & 20 & 20 & 40 & 6.99999999997925e-06 & 1.70000000000448e-05 & 1.13719e-10 \\
        newton & backtracking\_armijo & 5000 & 254756 & 15000 & 0.744671209268125 & 0.85835079632731 & 0.571970007227856 \\
        newton & wolfe\_strong & 3203 & 38030 & 3 & 6.99999999997925e-06 & 1.70000000000448e-05 & 1.13719e-10 \\
        newton & bisection\_wolfe\_weak & 5000 & 255769 & 260768 & 0.775276138921543 & 0.820599277205534 & 0.654647202982558 \\
        newton & bisection\_goldstein & 5000 & 509905 & 15000 & 0.775276138921834 & 0.820599277206036 & 0.654647202982856 \\
        newton & hanger\_zhang\_backtracking\_armijo & 22 & 46 & 65 & 6.99999999997925e-06 & 1.70000000000448e-05 & 1.13719e-10 \\
        newton & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 258955 & 263954 & 0.843304070256895 & 0.938240682390807 & 0.721844032454533 \\
        newton & hanger\_zhang\_wolfe\_strong & 74 & 457 & 3 & 6.99999999997925e-06 & 1.70000000000448e-05 & 1.13719e-10 \\
        newton & hanger\_zhang\_bisection\_goldstein & 5000 & 508891 & 15000 & 0.843304902801417 & 0.938241557861276 & 0.721845208848718 \\
        newton & grippo\_backtracking\_armijo & 21 & 43 & 62 & 6.99999999997925e-06 & 1.70000000000448e-05 & 1.13719e-10 \\
        newton & grippo\_bisection\_wolfe\_weak & 40 & 122 & 162 & 6.99999999997925e-06 & 1.70000000002668e-05 & 1.13719e-10 \\
        newton & grippo\_wolfe\_strong & 74 & 457 & 3 & 6.99999999997925e-06 & 1.70000000000448e-05 & 1.13719e-10 \\
        newton & grippo\_bisection\_goldstein & 40 & 165 & 119 & 6.99999999997925e-06 & 1.70000000002668e-05 & 1.13719e-10 \\
        steepest & none & 5000 & 5001 & 5000 & 2.87560123195337 & 1.29213612397107 & 14.3013587751244 \\
        steepest & backtracking\_armijo & 5000 & 17944 & 10000 & 6.99999904985038e-06 & 1.69999964657608e-05 & 1.13718999999998e-10 \\
        steepest & wolfe\_strong & 5000 & 17923 & 1 & 6.99999931175199e-06 & 1.69999974108936e-05 & 1.13718999999999e-10 \\
        steepest & bisection\_wolfe\_weak & 5000 & 17923 & 1 & inf & inf & inf \\
        steepest & bisection\_goldstein & 5000 & 17923 & 1 & inf & inf & inf \\
        steepest & hanger\_zhang\_backtracking\_armijo & 5000 & 17884 & 10000 & 0.0482912325223648 & 0.0337730969944426 & 0.00837436667822777 \\
        steepest & hanger\_zhang\_bisection\_wolfe\_weak & 5000 & 17884 & 10000 & inf & inf & inf \\
        steepest & hanger\_zhang\_wolfe\_strong & 5000 & 17903 & 4 & 6.99999937248119e-06 & 1.6999997437761e-05 & 1.13718999999999e-10 \\
        steepest & hanger\_zhang\_bisection\_goldstein & 5000 & 17903 & 4 & inf & inf & inf \\
        steepest & grippo\_backtracking\_armijo & 5000 & 17928 & 10000 & 6.99999918407634e-06 & 1.69999972122747e-05 & 1.13718999999999e-10 \\
        steepest & grippo\_bisection\_wolfe\_weak & 5000 & 19988 & 19987 & 6.99999944064889e-06 & 1.70000003533177e-05 & 1.13718999999999e-10 \\
        steepest & grippo\_wolfe\_strong & 5000 & 17903 & 4 & 6.99999937248119e-06 & 1.6999997437761e-05 & 1.13718999999999e-10 \\
        steepest & grippo\_bisection\_goldstein & 5000 & 17903 & 4 & inf & inf & inf \\
\end{tabular}}
\caption{f8}
\label{table:f8}
\end{table}

\clearpage


\subsubsection{Conclusions}

\begin{itemize}
    \item Without any step search method and using a fixed step length of 1, the steepest descent wasn't able to minimize the function. Due to the very high values of the gradient along with the step length, the algorithm has complete diverged and the x reached to Inf even within the first iterations.
    
    \item Without any step search method, the Newton method converged very close to the theoretical solution of $[1,1]^T$ in 5 iterations for the starting point of $[1.2,1.2]^T$ and in 6 for $[-1.2, 1]^T$.
    
    \item Using the Armijo condition for the Newton Method has similar performance with the above method, but now we are moving more carefully and slowly. For the point $[1.2,1.2]^T$, we converged to a solution within 8 iterations. For the point $[-1.2, 1]$, we converged within 21 iterations.
        
    \item Using the Armijo condition for the steepest descent, we can notice that the step size is adjusted and now the algorithm hasn't diverged compared to the fixed step size method mentioned above. But it seems that it is advancing very slowly. Having a threshold of 100 maximum iterations, the algorithm didn't converged.
    

    \item A very special case of the last function tested above ($f_8$), is where the gradient of the function contains the square root of the coordinates. Thus if during the iterative approach, a point with negative coordinates will occur, the result of the gradient will have an imaginary field, causing the algorithm to break. In other words, it is possible to calculate inputs that are \textbf{outside of the domain of the function}. How to resolve this? (setting boundaries or using projections)

    The actual problem of the above was the initial step size value, that was usually ($a=1$). Thus initially, the $x+a*pk$ could result to a value outside of the domain of the function, causing the rest of the algorithm to fail. To keep the initial alpha value within the boundaries, we have added the function \verb|check_boundaries.m|.

    \item A thing to consider, is that when trying to calculate a step size to satisfy some conditions, we set a threshold of iterations. If the threshold is met (\textbf{max number of iterations}), then we still return the latest alpha value, that doesn't though satisfy the conditions, thus theoretically speaking the algorithm may not converge. How to resolve this edge case, where we exceed a certain number of iterations, since there should be a point where the algorithm needs to return.

    \item Steepest descent method usually has greater error values, because the direction vector $p_k$ isn't normalized with the hessian matrix as it is happening with the newton method and could have very large values that can be controlled by the choice of the step size ($a*pk$). But the step size configuration has a maximum number of iterations. For the backtracking armijo for example, based on the $rho$ value, we backtrack a for each iteration. If the initial a value is high and $rho$ isn't small enough and number of max iterations is small, then a value can be not small enough to reduce the effect of the direction vector. Thus, to reduce some 'Inf' values we could experiment with the choice of the aforementioned parameters. On the other hand, increasing the number of iterations trying to find a step size satisfying some conditions, can lead to very small values making the algorithm to stuck. If alpha values is found before the max number of iterations, then increasing the iterations of the \verb|newton| or the \verb|steepest descent| will lead to a better result (may the $a*pk$ be reasonable but the iterations not enough to calculate the next better $x$).

    \item For $f_6$, the algorithm diverges when using wolfe strong as step size method. The problem occurs because when searching for the step size, we reach maximum number iterations (20), before satisfying the conditions. Resulting with a not small enough value to counter the very large value of direction vector ($p_k$), thus making the product $a*pk$, a very large value, diverging the $x$.
    
\end{itemize} 


\section{Wrap up}

Every iterative algorithm for line search is based on:

\[x_{k+1} = x_k + a p_k\]

The research interest arises on the choice of the step size $\alpha$ and the direction $p_k$, the convergence, the rate of it and the derivative requirements (is the knowledge of first or second order derivatives required ?).

For the direction,  
the core idea of the line search methods lies into the Taylor approximation of a function near a point:

\[f(x_k + a p) = f(x_k) + a p^T \nabla f_k + \frac{1}{2} a^2 p^T \nabla^2 f(x_k + tp) p\]

Considering $\nabla^2 f$ as positive definitive, to decrease the function $f$, then our goal is to find $p$ such that
$min$ $p^T \nabla f_k$. By definition of the dot product ($min$ $|\nabla f_k| |p_k| cos \theta$), $p$ should be $p = - \nabla f_k / ||\nabla f_k||$. Thus the steepest descent method uses $p_k = - \nabla f_k$.

For the Newton method, to decrease the $f$, finding the root of the derivative of the Taylor expansion, the $p$ should be $p = - (\nabla^2 f_k) ^{-1} \nabla f_k$.

But calculating the $\nabla^2 f$ is an expensive step, so we can approximate it, using the quasi-Newton methods. For example, for the BFGS we have:

\begin{align}
    p_k &= -B_k^{-1} \nabla f_k \\
    M_{k+1} &= M_k + \frac{s_k s_k^T}{s_k^T y_k} - \frac{M_k y_k y_k^T M_k}{y_k^T M_k y_k} \\
    s_k &= x_{k+1} - x_k \\
    y_k &= \nabla f_{k+1} - \nabla f_k \\
    M_k &= B_k^{-1}
\end{align}

\textbf{Question}

What is the initial estimation of $B_K^{-1}$ to start the iterative approximation for then next steps?

\textbf{Answer}

The identity matrix.

\subsection{Convergence}

It can be shown from Zoutendijk's theorem that if the line search algorithm satisfies (weak) Wolfe's conditions (similar results also hold for strong Wolfe and Goldstein conditions) and has a search direction that makes an angle with the steepest descent direction that is bounded away from 90°, the algorithm is globally convergent. 

\subsection{Comparison of methods}

Comparison between steepest descent, Newton and quasi-Netwon methods:

\begin{itemize}
    \item Steepest descent method advantage is the usage of only first derivatives, and making it the least computationally expensive algorithm per iteration. The main disadvantage is the rate of convergence. It can be extremely slow.

    \item Convergence is dependent on both the step size $\alpha$ and the direction $p_k$. Usually for methods to converge, step size should satisfy the wolfe conditions and for the $p_k$, should not be close to orthogonality with the $\nabla f_k$.
    
    \item Newton's method advantage is the fast convergence (quadratic). The disadvantage is the need of the second derivatives (the hessian matrix). 
    
    \item Newton's method step size is usually 1. It doesn't require sophisticated algorithms like the steepest descent, to find a proper step size.
    
    \item Quasi-Newton method aims to solve the problems of the two aforementioned methods. Same as the Newton technique, but the hessian matrix is estimated using the knowledge of the previous calculated first derivatives. The drawback of approximation is that the convergence from quadratic becomes superlinear, but still usually faster than steepest descent.
    
\end{itemize}

\label{code}
\section{Code}

\textbf{demo.m}
\lstinputlisting{code/demo.m}
% \lstinputlisting{code/simulation.ipynb}
\textbf{tests.m}
\lstinputlisting{code/tests.m}
\textbf{simulation1.m}
\lstinputlisting{code/simulation1.m}
\textbf{simulation2.m}
\lstinputlisting{code/simulation2.m}
\textbf{simulation.m}
\lstinputlisting{code/simulation.m}


\subsection{utils}
\textbf{check\_boundaries.m}
\lstinputlisting{code/utils/check_boundaries.m}
\textbf{is\_vector.m}
\lstinputlisting{code/utils/is_vector.m}
\textbf{plot\_line\_search1.m}
\lstinputlisting{code/utils/plot_line_search1.m}
\textbf{vector\_function.m}
\lstinputlisting{code/utils/vector_function.m}

\subsubsection{line\_search\_methods}
\textbf{newton.m}
\lstinputlisting{code/utils/line_search_methods/newton.m}
\textbf{steepest\_descent.m}
\lstinputlisting{code/utils/line_search_methods/steepest_descent.m}

\subsubsection{step\_size}
\textbf{backtracking\_armijo.m}
\lstinputlisting{code/utils/step_size/backtracking_armijo.m}
\textbf{bisection\_curvature.m}
\lstinputlisting{code/utils/step_size/bisection_curvature.m}
\textbf{wolfe\_strong.m}
\lstinputlisting{code/utils/step_size/wolfe_strong.m}
\textbf{armijo\_condition.m}
\lstinputlisting{code/utils/step_size/armijo_condition.m}
\textbf{hanger\_zhang\_attrs\_attrs.m}
\lstinputlisting{code/utils/step_size/hanger_zhang_attrs.m}
\textbf{step\_size.m}
\lstinputlisting{code/utils/step_size/step_size.m}



\clearpage

\label{plots}
\section{Plots}

\includepdf[pages=-]{simulation.pdf}

\clearpage



\bibliographystyle{plain}
\bibliography{refs.bib}


\end{document}



